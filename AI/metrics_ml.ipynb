{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "metrics_ml.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thefr33radical/codeblue/blob/master/AI/metrics_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqowXySnoLRy"
      },
      "source": [
        "### Loss functions\n",
        "\n",
        "* Loss function represents cost associated with a event. Mathematically it maps values of 2 or more variable to a real number.\n",
        "* It shows how accurate a model is from the ground truth.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpw4p5yE65xu"
      },
      "source": [
        "# r2 score\n",
        "'''\n",
        "Defnition : R-squared is a statistical measure of how close the data are to the fitted regression line.\n",
        "It is also known as the coefficient of determination, or the coefficient of multiple determination for multiple regression.\n",
        "\n",
        "Possible Values:\n",
        "\n",
        "if R2 < 0 : Horizontal line explains the data better than the model.\n",
        "if R2 = 0 : HOrizontal line explains the data equally as your model.\n",
        "if R2 > 0 : Explains variance\n",
        "\n",
        "\n",
        "  References:\n",
        "* https://stats.stackexchange.com/questions/183265/what-does-negative-r-squared-mean\n",
        "* https://blog.minitab.com/blog/adventures-in-statistics-2/regression-analysis-how-do-i-interpret-r-squared-and-assess-the-goodness-of-fit\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emc7aDBH7i7H"
      },
      "source": [
        "# RMSE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKgzGM0U7lTl"
      },
      "source": [
        "# MSE - Mean Squared Error\n",
        "# Sensitive to outliers, use when outliers are minimum.\n",
        "# Great to penalize/learn outliers.  Outliers get exponential weightage.\n",
        "# Always gives one solution, hence stable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "y=np.array([1,2,3,4],dtype=int)\n",
        "Yp=np.array([1,20,3,4],dtype=int)\n",
        "\n",
        "def MSE(y,Yp):\n",
        "  return sum(np.square((y-Yp)))/len(y)\n",
        "\n",
        "print(MSE(y,Yp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjB_AwKO7p9p"
      },
      "source": [
        "# MAE - Mean Absolute Error\n",
        "# Insensitive to outliers, use when outliers need to be ignored.\n",
        "# All errors get equal weightage.\n",
        "# Multiple solution, hence unstable\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "y=np.array([1,2,3,4],dtype=int)\n",
        "Yp=np.array([1,20,3,4],dtype=int)\n",
        "\n",
        "def MAE(y,Yp):\n",
        "  return sum(np.abs((y-Yp)))/len(y)\n",
        "\n",
        "print(MAE(y,Yp))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}